{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a01796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3efb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(\"tripadvisor_hotel_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcee2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_review_text(row):\n",
    "    conjoined_regex = r'(\\w{2,}[\\.\\*\\'/]\\w{2,})\\b'\n",
    "    trailing_dash_comma_regex = r'(\\w+[-,])\\s'\n",
    "    trailing_period_regex = r'(\\w+\\.)\\s'\n",
    "    review = row['Review']\n",
    "    \n",
    "    # 1. Split conjoined words\n",
    "    conjoined_match = re.search(conjoined_regex, review)\n",
    "    if conjoined_match:\n",
    "       for word in conjoined_match.groups():\n",
    "           review = review.replace(word, word.replace('.', ' '))\n",
    "           review = review.replace(word, word.replace('*', ' '))\n",
    "           review = review.replace(word, word.replace('/', ' '))\n",
    "           review = review.replace(word, word.replace('\\'', ' '))\n",
    "    \n",
    "    # 2a. Remove n't and not\n",
    "    review = review.replace('n\\'t', '').replace('not', '')\n",
    "\n",
    "    # 2. Remove trailing dashes, commas\n",
    "    trailing_dash_comma_match = re.search(trailing_dash_comma_regex, review)\n",
    "    if trailing_dash_comma_match:\n",
    "       for word in trailing_dash_comma_match.groups():\n",
    "           review = review.replace(word, word.rstrip('-,'))\n",
    "            \n",
    "    # 3. Remove numbers\n",
    "    review = ' '.join([word for word in review.split() if not word.isdigit()])\n",
    "\n",
    "    \n",
    "    \n",
    "    # 4a. Lemmatization using WordNetLemmatizer\n",
    "    review = ' '.join([lemmatizer.lemmatize(w, 'v') for w in review.split()])\n",
    "    \n",
    "    # 4b. Stemming\n",
    "    # review = ' '.join([stemmer.stem(w) for w in review.split()])\n",
    "    \n",
    "    return review\n",
    "    \n",
    "reviews_df[\"Review\"] = reviews_df.apply(clean_review_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c19370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating_to_sentiment(row):\n",
    "    rating = row['Rating']\n",
    "    if rating in [1,2]:\n",
    "        return \"Negative\"\n",
    "    elif rating in [3]:\n",
    "        return \"Neutral\"\n",
    "    elif rating in [4,5]:\n",
    "        return \"Positive\"\n",
    "    return \"Unknown\"\n",
    "def map_rating_to_sentiment_score(row):\n",
    "    rating = row['Rating']\n",
    "    if rating in [1,2]:\n",
    "        return 1\n",
    "    elif rating in [3]:\n",
    "        return 2\n",
    "    elif rating in [4,5]:\n",
    "        return 3\n",
    "    return -1\n",
    "reviews_df['Sentiment'] = reviews_df.apply(map_rating_to_sentiment, axis=1)\n",
    "reviews_df['Sentiment Score'] = reviews_df.apply(map_rating_to_sentiment_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f677000",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df = 5,          # Minimum document frequency (i.e. ignore all words with less than 5 occurrences)\n",
    "    max_df = 0.8,        # Maximum document frequency (i.e. ignore all words that account for 80% of the corpus size)\n",
    "    sublinear_tf = True, # Apply sublinear term frequency scaling\n",
    "    ngram_range=(1,3)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfc9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = vectorizer.fit(reviews_df[\"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42942e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_reviews = len(reviews_df)\n",
    "sections = [int(0.8 * no_of_reviews), int(0.9 * no_of_reviews)]\n",
    "\n",
    "reviews_train, reviews_test, reviews_val = np.split(\n",
    "    ary = reviews_df[\"Review\"],             # Array to split (i.e. our DataFrame of reviews)\n",
    "    indices_or_sections = sections          # Sections to split (i.e. split at 80% and 90% mark)\n",
    ")\n",
    "X_train, X_test, X_val = (\n",
    "    vectorizer.transform(reviews_train),\n",
    "    vectorizer.transform(reviews_test),\n",
    "    vectorizer.transform(reviews_val),\n",
    ")\n",
    "y_rating_train, y_rating_test, y_rating_val = np.split(\n",
    "    ary = reviews_df[\"Rating\"],             # Array to split (i.e. our DataFrame of reviews)\n",
    "    indices_or_sections = sections          # Sections to split (i.e. split at 80% and 90% mark)\n",
    ")\n",
    "y_sentiment_train, y_sentiment_test, y_sentiment_val = np.split(\n",
    "    ary = reviews_df[\"Sentiment Score\"],             # Array to split (i.e. our DataFrame of reviews)\n",
    "    indices_or_sections = sections          # Sections to split (i.e. split at 80% and 90% mark)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b3dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faf377fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes (Rating)...\n",
      "- Training Time: 0.03s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Naive Bayes (Rating)...')\n",
    "rating_train_start = time.perf_counter()\n",
    "rating_model = MultinomialNB(force_alpha=True)\n",
    "rating_model.fit(X_train, y_rating_train)\n",
    "rating_train_end = time.perf_counter()\n",
    "print(f'- Training Time: {rating_train_end - rating_train_start:.2f}s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b6b6a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes (Sentiment)...\n",
      "- Training Time: 0.03s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Naive Bayes (Sentiment)...')\n",
    "sentiment_train_start = time.perf_counter()\n",
    "sentiment_model = MultinomialNB(force_alpha=True)\n",
    "sentiment_model.fit(X_train, y_sentiment_train)\n",
    "sentiment_train_end = time.perf_counter()\n",
    "print(f'- Training Time: {rating_train_end - rating_train_start:.2f}s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d917e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50b3c815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Naive Bayes Model (Rating) on Test Data...\n",
      "Performance:\n",
      "- Accuracy: 53.64\n",
      "- F1: 41.79\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       103\n",
      "           2       0.00      0.00      0.00       143\n",
      "           3       0.00      0.00      0.00       207\n",
      "           4       0.36      0.15      0.22       569\n",
      "           5       0.56      0.98      0.71      1027\n",
      "\n",
      "    accuracy                           0.54      2049\n",
      "   macro avg       0.18      0.23      0.19      2049\n",
      "weighted avg       0.38      0.54      0.42      2049\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_start = time.perf_counter()\n",
    "print(f'\\nTesting Naive Bayes Model (Rating) on Test Data...')\n",
    "test_predictions = rating_model.predict(X_test)\n",
    "test_end = time.perf_counter()\n",
    "test_accuracy = accuracy_score(y_rating_test, test_predictions)\n",
    "test_f1 = f1_score(y_rating_test, test_predictions, average='weighted', zero_division=0)\n",
    "print(f'Performance:')\n",
    "print(f'- Accuracy: {test_accuracy*100:.2f}')\n",
    "print(f'- F1: {test_f1*100:.2f}')\n",
    "print(f'- Test Prediction Time: {test_end - test_start:.2f}s')\n",
    "print(f'- Classification Report:')\n",
    "print(classification_report(y_rating_test, test_predictions, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "706cea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Naive Bayes Model (Sentiment) on Test Data...\n",
      "Performance:\n",
      "- Accuracy: 79.21\n",
      "- F1: 71.11\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.11      0.20       246\n",
      "           2       0.00      0.00      0.00       207\n",
      "           3       0.79      1.00      0.88      1596\n",
      "\n",
      "    accuracy                           0.79      2049\n",
      "   macro avg       0.58      0.37      0.36      2049\n",
      "weighted avg       0.73      0.79      0.71      2049\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_start = time.perf_counter()\n",
    "print(f'\\nTesting Naive Bayes Model (Sentiment) on Test Data...')\n",
    "test_predictions = sentiment_model.predict(X_test)\n",
    "test_end = time.perf_counter()\n",
    "test_accuracy = accuracy_score(y_sentiment_test, test_predictions)\n",
    "test_f1 = f1_score(y_sentiment_test, test_predictions, average='weighted', zero_division=0)\n",
    "print(f'Performance:')\n",
    "print(f'- Accuracy: {test_accuracy*100:.2f}')\n",
    "print(f'- F1: {test_f1*100:.2f}')\n",
    "print(f'- Test Prediction Time: {test_end - test_start:.2f}s')\n",
    "print(f'- Classification Report:')\n",
    "print(classification_report(y_sentiment_test, test_predictions, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d26fa6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Naive Bayes Model (Rating) on Validation Data...\n",
      "Performance:\n",
      "- Accuracy: 51.02\n",
      "- F1: 38.97\n",
      "- Test Prediction Time: 0.01s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       114\n",
      "           2       0.00      0.00      0.00       166\n",
      "           3       0.00      0.00      0.00       204\n",
      "           4       0.32      0.15      0.20       585\n",
      "           5       0.54      0.98      0.69       981\n",
      "\n",
      "    accuracy                           0.51      2050\n",
      "   macro avg       0.17      0.22      0.18      2050\n",
      "weighted avg       0.35      0.51      0.39      2050\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_start = time.perf_counter()\n",
    "print(f'\\nTesting Naive Bayes Model (Rating) on Validation Data...')\n",
    "val_predictions = rating_model.predict(X_val)\n",
    "val_end = time.perf_counter()\n",
    "val_accuracy = accuracy_score(y_rating_val, val_predictions)\n",
    "val_f1 = f1_score(y_rating_val, val_predictions, average='weighted', zero_division=0)\n",
    "print(f'Performance:')\n",
    "print(f'- Accuracy: {val_accuracy*100:.2f}')\n",
    "print(f'- F1: {val_f1*100:.2f}')\n",
    "print(f'- Test Prediction Time: {val_end - val_start:.2f}s')\n",
    "print(f'- Classification Report:')\n",
    "print(classification_report(y_rating_val, val_predictions, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "300b548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Naive Bayes Model (Sentiment) on Validation Data...\n",
      "Performance:\n",
      "- Accuracy: 77.61\n",
      "- F1: 68.87\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.09      0.16       280\n",
      "           2       0.00      0.00      0.00       204\n",
      "           3       0.77      1.00      0.87      1566\n",
      "\n",
      "    accuracy                           0.78      2050\n",
      "   macro avg       0.59      0.36      0.35      2050\n",
      "weighted avg       0.73      0.78      0.69      2050\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_start = time.perf_counter()\n",
    "print(f'\\nTesting Naive Bayes Model (Sentiment) on Validation Data...')\n",
    "val_predictions = sentiment_model.predict(X_val)\n",
    "val_end = time.perf_counter()\n",
    "val_accuracy = accuracy_score(y_sentiment_val, val_predictions)\n",
    "val_f1 = f1_score(y_sentiment_val, val_predictions, average='weighted', zero_division=0)\n",
    "print(f'Performance:')\n",
    "print(f'- Accuracy: {val_accuracy*100:.2f}')\n",
    "print(f'- F1: {val_f1*100:.2f}')\n",
    "print(f'- Test Prediction Time: {val_end - val_start:.2f}s')\n",
    "print(f'- Classification Report:')\n",
    "print(classification_report(y_sentiment_val, val_predictions, zero_division=0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87f9c9",
   "metadata": {},
   "source": [
    "## Evaluation of Naive Bayes on Other Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c88be4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_food_df = pd.read_csv(\"./amazon_fine_food_reviews.csv\")\n",
    "play_store_df = pd.read_csv(\"./google_play_store_reviews.csv\")\n",
    "clothing_df = pd.read_csv(\"./Womens Clothing E-Commerce Reviews.csv\")\n",
    "mobile_phones_df = pd.read_csv(\"./Amazon_Unlocked_Mobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de152702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22641 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               22641 non-null  int64 \n",
      " 1   Clothing ID              22641 non-null  int64 \n",
      " 2   Age                      22641 non-null  int64 \n",
      " 3   Title                    19675 non-null  object\n",
      " 4   Review Text              22641 non-null  object\n",
      " 5   Rating                   22641 non-null  int64 \n",
      " 6   Recommended IND          22641 non-null  int64 \n",
      " 7   Positive Feedback Count  22641 non-null  int64 \n",
      " 8   Division Name            22628 non-null  object\n",
      " 9   Department Name          22628 non-null  object\n",
      " 10  Class Name               22628 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 413778 entries, 0 to 413839\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Product Name  413778 non-null  object \n",
      " 1   Brand Name    348623 non-null  object \n",
      " 2   Price         407848 non-null  float64\n",
      " 3   Rating        413778 non-null  int64  \n",
      " 4   Reviews       413778 non-null  object \n",
      " 5   Review Votes  401482 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 22.1+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_clothing_df = clothing_df.dropna(subset=[\"Review Text\"])\n",
    "cleaned_clothing_df.info()\n",
    "\n",
    "cleaned_mobile_phones_df = mobile_phones_df.dropna(subset=[\"Reviews\"])\n",
    "cleaned_mobile_phones_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90166b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_food_vectorized = vectorizer.transform(fine_food_df[\"Text\"])\n",
    "play_store_vectorized = vectorizer.transform(play_store_df[\"content\"])\n",
    "clothing_vectorized = vectorizer.transform(cleaned_clothing_df[\"Review Text\"])\n",
    "mobile_phones_vectorized = vectorizer.transform(cleaned_mobile_phones_df[\"Reviews\"])\n",
    "\n",
    "y_rating_ff = fine_food_df[\"Score\"]\n",
    "y_rating_ps = play_store_df[\"score\"]\n",
    "y_rating_cl = cleaned_clothing_df[\"Rating\"]\n",
    "y_rating_mp = cleaned_mobile_phones_df[\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e687a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating_to_sentiment_score(rating):\n",
    "    if rating in [1,2]:\n",
    "        return 1\n",
    "    elif rating in [3]:\n",
    "        return 2\n",
    "    elif rating in [4,5]:\n",
    "        return 3\n",
    "    return -1\n",
    "\n",
    "y_sentiment_ff = y_rating_ff.apply(map_rating_to_sentiment_score)    \n",
    "y_sentiment_ps = y_rating_ps.apply(map_rating_to_sentiment_score)\n",
    "y_sentiment_cl = y_rating_cl.apply(map_rating_to_sentiment_score)    \n",
    "y_sentiment_mp = y_rating_mp.apply(map_rating_to_sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba8f4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    'Amazon Fine Food Reviews',\n",
    "    'Google Play Store Reviews',\n",
    "    'Women\\'s E-Commerce Clothing Reviews',\n",
    "    'Amazon Reviews of Unlocked Mobile Phones'\n",
    "]\n",
    "dataset_x = {\n",
    "    'Amazon Fine Food Reviews': fine_food_vectorized,\n",
    "    'Google Play Store Reviews': play_store_vectorized,\n",
    "    'Women\\'s E-Commerce Clothing Reviews': clothing_vectorized,\n",
    "    'Amazon Reviews of Unlocked Mobile Phones': mobile_phones_vectorized\n",
    "}\n",
    "dataset_y_rating = {\n",
    "    'Amazon Fine Food Reviews': y_rating_ff,\n",
    "    'Google Play Store Reviews': y_rating_ps,\n",
    "    'Women\\'s E-Commerce Clothing Reviews': y_rating_cl,\n",
    "    'Amazon Reviews of Unlocked Mobile Phones': y_rating_mp\n",
    "}\n",
    "dataset_y_sentiment = {\n",
    "    'Amazon Fine Food Reviews': y_sentiment_ff,\n",
    "    'Google Play Store Reviews': y_sentiment_ps,\n",
    "    'Women\\'s E-Commerce Clothing Reviews': y_sentiment_cl,\n",
    "    'Amazon Reviews of Unlocked Mobile Phones': y_sentiment_mp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50534e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Naive Bayes Model (Rating) on Amazon Fine Food Reviews...\n",
      "Performance:\n",
      "- Accuracy: 63.27\n",
      "- F1: 50.91\n",
      "- Test Prediction Time: 0.17s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     52268\n",
      "           2       0.00      0.00      0.00     29769\n",
      "           3       0.00      0.00      0.00     42640\n",
      "           4       0.22      0.05      0.08     80655\n",
      "           5       0.65      0.98      0.78    363122\n",
      "\n",
      "    accuracy                           0.63    568454\n",
      "   macro avg       0.17      0.21      0.17    568454\n",
      "weighted avg       0.44      0.63      0.51    568454\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Sentiment) on Amazon Fine Food Reviews...\n",
      "Performance:\n",
      "- Accuracy: 78.07\n",
      "- F1: 68.45\n",
      "- Test Prediction Time: 0.11s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.00     82037\n",
      "           2       0.00      0.00      0.00     42640\n",
      "           3       0.78      1.00      0.88    443777\n",
      "\n",
      "    accuracy                           0.78    568454\n",
      "   macro avg       0.59      0.33      0.29    568454\n",
      "weighted avg       0.75      0.78      0.68    568454\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Rating) on Google Play Store Reviews...\n",
      "Performance:\n",
      "- Accuracy: 23.73\n",
      "- F1: 11.19\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.00      0.01      2506\n",
      "           2       0.00      0.00      0.00      2344\n",
      "           3       0.00      0.00      0.00      1991\n",
      "           4       0.22      0.07      0.10      2775\n",
      "           5       0.24      0.96      0.38      2879\n",
      "\n",
      "    accuracy                           0.24     12495\n",
      "   macro avg       0.22      0.21      0.10     12495\n",
      "weighted avg       0.23      0.24      0.11     12495\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Sentiment) on Google Play Store Reviews...\n",
      "Performance:\n",
      "- Accuracy: 45.36\n",
      "- F1: 28.44\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.00      0.01      4850\n",
      "           2       0.00      0.00      0.00      1991\n",
      "           3       0.45      1.00      0.62      5654\n",
      "\n",
      "    accuracy                           0.45     12495\n",
      "   macro avg       0.46      0.33      0.21     12495\n",
      "weighted avg       0.57      0.45      0.28     12495\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Rating) on Women's E-Commerce Clothing Reviews...\n",
      "Performance:\n",
      "- Accuracy: 55.21\n",
      "- F1: 40.51\n",
      "- Test Prediction Time: 0.01s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       821\n",
      "           2       0.00      0.00      0.00      1549\n",
      "           3       0.00      0.00      0.00      2823\n",
      "           4       0.28      0.03      0.05      4908\n",
      "           5       0.56      0.99      0.71     12540\n",
      "\n",
      "    accuracy                           0.55     22641\n",
      "   macro avg       0.17      0.20      0.15     22641\n",
      "weighted avg       0.37      0.55      0.41     22641\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Sentiment) on Women's E-Commerce Clothing Reviews...\n",
      "Performance:\n",
      "- Accuracy: 77.06\n",
      "- F1: 67.08\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00      2370\n",
      "           2       0.00      0.00      0.00      2823\n",
      "           3       0.77      1.00      0.87     17448\n",
      "\n",
      "    accuracy                           0.77     22641\n",
      "   macro avg       0.26      0.33      0.29     22641\n",
      "weighted avg       0.59      0.77      0.67     22641\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Rating) on Amazon Reviews of Unlocked Mobile Phones...\n",
      "Performance:\n",
      "- Accuracy: 53.50\n",
      "- F1: 39.44\n",
      "- Test Prediction Time: 0.06s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.00      0.00     72337\n",
      "           2       0.00      0.00      0.00     24724\n",
      "           3       0.00      0.00      0.00     31763\n",
      "           4       0.23      0.07      0.10     61374\n",
      "           5       0.55      0.97      0.70    223580\n",
      "\n",
      "    accuracy                           0.54    413778\n",
      "   macro avg       0.35      0.21      0.16    413778\n",
      "weighted avg       0.50      0.54      0.39    413778\n",
      "\n",
      "\n",
      "\n",
      "Testing Naive Bayes Model (Sentiment) on Amazon Reviews of Unlocked Mobile Phones...\n",
      "Performance:\n",
      "- Accuracy: 68.92\n",
      "- F1: 56.29\n",
      "- Test Prediction Time: 0.05s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.00      0.00     97061\n",
      "           2       0.00      0.00      0.00     31763\n",
      "           3       0.69      1.00      0.82    284954\n",
      "\n",
      "    accuracy                           0.69    413778\n",
      "   macro avg       0.55      0.33      0.27    413778\n",
      "weighted avg       0.70      0.69      0.56    413778\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    X_dataset = dataset_x[dataset_name]\n",
    "    y_rating_dataset = dataset_y_rating[dataset_name]\n",
    "    y_sentiment_dataset = dataset_y_sentiment[dataset_name]\n",
    "    \n",
    "    ds_start = time.perf_counter()\n",
    "    print(f'\\nTesting Naive Bayes Model (Rating) on {dataset_name}...')\n",
    "    ds_predictions = rating_model.predict(X_dataset)\n",
    "    ds_end = time.perf_counter()\n",
    "    ds_accuracy = accuracy_score(y_rating_dataset, ds_predictions)\n",
    "    ds_f1 = f1_score(y_rating_dataset, ds_predictions, average='weighted', zero_division=0)\n",
    "    print(f'Performance:')\n",
    "    print(f'- Accuracy: {ds_accuracy*100:.2f}')\n",
    "    print(f'- F1: {ds_f1*100:.2f}')\n",
    "    print(f'- Test Prediction Time: {ds_end - ds_start:.2f}s')\n",
    "    print(f'- Classification Report:')\n",
    "    print(classification_report(y_rating_dataset, ds_predictions, zero_division=0))\n",
    "    print()\n",
    "\n",
    "\n",
    "    ds_start = time.perf_counter()\n",
    "    print(f'\\nTesting Naive Bayes Model (Sentiment) on {dataset_name}...')\n",
    "    ds_predictions = sentiment_model.predict(X_dataset)\n",
    "    ds_end = time.perf_counter()\n",
    "    ds_accuracy = accuracy_score(y_sentiment_dataset, ds_predictions)\n",
    "    ds_f1 = f1_score(y_sentiment_dataset, ds_predictions, average='weighted', zero_division=0)\n",
    "    print(f'Performance:')\n",
    "    print(f'- Accuracy: {ds_accuracy*100:.2f}')\n",
    "    print(f'- F1: {ds_f1*100:.2f}')\n",
    "    print(f'- Test Prediction Time: {ds_end - ds_start:.2f}s')\n",
    "    print(f'- Classification Report:')\n",
    "    print(classification_report(y_sentiment_dataset, ds_predictions, zero_division=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b56b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
