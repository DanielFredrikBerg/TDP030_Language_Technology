{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with Extensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reviews.csv file into a Pandas dataframe\n",
    "reviews_df = pd.read_csv('tripadvisor_hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_info(text):\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    repls = ('.', ' '), ('did n\\'t', 'didn\\'t'), ('wo n\\'t', 'won\\'t'), ('do n\\'t', 'don\\'t'), ('n\\'t', ''), ('*', ''), (',', ' '), ('\\'', ' '), ('-', ' ')\n",
    "    return reduce(lambda a, kv: a.replace(*kv), repls, text)\n",
    "\n",
    "def recode_score(score):\n",
    "    if score in [1, 2]:\n",
    "        return 1\n",
    "    elif score == 3:\n",
    "        return 2\n",
    "    elif score in [4, 5]:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the review text and the corresponding scores from the dataframe\n",
    "reviews_df['Sentiment Score'] = reviews_df['Rating'].apply(recode_score)\n",
    "reviews_df['Review'] = reviews_df['Review'].apply(clean_review_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df = 5,          # Minimum document frequency (i.e. ignore all words with less than 5 occurrences)\n",
    "    max_df = 0.8,        # Maximum document frequency (i.e. ignore all words that account for 80% of the corpus size)\n",
    "    sublinear_tf = True, # Apply sublinear term frequency scaling\n",
    "    ngram_range=(1,3)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_reviews = len(reviews_df)\n",
    "sections = [int(0.8 * no_of_reviews), int(0.9 * no_of_reviews)]\n",
    "\n",
    "reviews_train, reviews_test, reviews_val = np.split(\n",
    "    ary = reviews_df[\"Review\"],             # Array to split (i.e. our DataFrame of reviews)\n",
    "    indices_or_sections = sections          # Sections to split (i.e. split at 80% and 90% mark)\n",
    ")\n",
    "vectorizer.fit(reviews_train)\n",
    "X_train, X_test, X_val = (\n",
    "    vectorizer.transform(reviews_train),\n",
    "    vectorizer.transform(reviews_test),\n",
    "    vectorizer.transform(reviews_val),\n",
    ")\n",
    "y_rating_train, y_rating_test, y_rating_val = np.split(\n",
    "    ary = reviews_df[\"Rating\"],             # Array to split (i.e. our DataFrame of reviews)\n",
    "    indices_or_sections = sections          # Sections to split (i.e. split at 80% and 90% mark)\n",
    ")\n",
    "y_sentiment_train, y_sentiment_test, y_sentiment_val = np.split(\n",
    "    ary = reviews_df[\"Sentiment Score\"],             # Array to split (i.e. our DataFrame of reviews)\n",
    "    indices_or_sections = sections          # Sections to split (i.e. split at 80% and 90% mark)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune\n",
    "params = {'max_depth': [5, 10, 20, None],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [1, 2, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 3 ... 4 4 4]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.34       103\n",
      "           2       0.25      0.09      0.13       143\n",
      "           3       0.20      0.16      0.18       207\n",
      "           4       0.37      0.38      0.38       569\n",
      "           5       0.65      0.72      0.69      1027\n",
      "\n",
      "    accuracy                           0.51      2049\n",
      "   macro avg       0.37      0.34      0.34      2049\n",
      "weighted avg       0.49      0.51      0.49      2049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the DecisionTreeClassifier class\n",
    "rating_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a GridSearchCV object to search over the hyperparameters\n",
    "dt_rating_grid_search = GridSearchCV(rating_clf, params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "dt_rating_grid_search.fit(X_train, y_rating_train)\n",
    "\n",
    "# Use the best estimator to make predictions on the testing data\n",
    "dt_rating_best_clf = dt_rating_grid_search.best_estimator_\n",
    "dt_rating_test_predictions = dt_rating_best_clf.predict(X_test)\n",
    "print(dt_rating_test_predictions, end='\\n\\n')\n",
    "# Print the classification report\n",
    "print(classification_report(y_rating_test, dt_rating_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 1 ... 3 3 3]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.44      0.47       246\n",
      "           2       0.31      0.10      0.15       207\n",
      "           3       0.85      0.94      0.89      1596\n",
      "\n",
      "    accuracy                           0.79      2049\n",
      "   macro avg       0.55      0.49      0.50      2049\n",
      "weighted avg       0.75      0.79      0.76      2049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the DecisionTreeClassifier class\n",
    "sentiment_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a GridSearchCV object to search over the hyperparameters\n",
    "dt_sentiment_grid_search = GridSearchCV(sentiment_clf, params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "dt_sentiment_grid_search.fit(X_train, y_sentiment_train)\n",
    "\n",
    "# Use the best estimator to make predictions on the testing data\n",
    "dt_sentiment_best_clf = dt_sentiment_grid_search.best_estimator_\n",
    "dt_sentiment_test_predictions = dt_sentiment_best_clf.predict(X_test)\n",
    "print(dt_sentiment_test_predictions, end='\\n\\n')\n",
    "# Print the classification report\n",
    "print(classification_report(y_sentiment_test, dt_sentiment_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 5 ... 4 2 5]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.45      0.41       114\n",
      "           2       0.32      0.11      0.16       166\n",
      "           3       0.23      0.17      0.20       204\n",
      "           4       0.40      0.39      0.39       585\n",
      "           5       0.64      0.75      0.69       981\n",
      "\n",
      "    accuracy                           0.52      2050\n",
      "   macro avg       0.39      0.37      0.37      2050\n",
      "weighted avg       0.49      0.52      0.50      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_rating_val_predictions = dt_rating_best_clf.predict(X_val)\n",
    "print(dt_rating_val_predictions, end='\\n\\n')\n",
    "# Print the classification report\n",
    "print(classification_report(y_rating_val, dt_rating_val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 3 ... 1 3 3]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54       280\n",
      "           2       0.19      0.05      0.08       204\n",
      "           3       0.85      0.93      0.89      1566\n",
      "\n",
      "    accuracy                           0.79      2050\n",
      "   macro avg       0.53      0.50      0.50      2050\n",
      "weighted avg       0.74      0.79      0.76      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_sentiment_val_predictions = dt_sentiment_best_clf.predict(X_val)\n",
    "print(dt_sentiment_val_predictions, end='\\n\\n')\n",
    "# Print the classification report\n",
    "print(classification_report(y_sentiment_val, dt_sentiment_val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Decision Tree on Other Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_food_df = pd.read_csv(\"./amazon_fine_food_reviews.csv\")\n",
    "play_store_df = pd.read_csv(\"./google_play_store_reviews.csv\")\n",
    "clothing_df = pd.read_csv(\"./Womens Clothing E-Commerce Reviews.csv\")\n",
    "mobile_phones_df = pd.read_csv(\"./Amazon_Unlocked_Mobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22641 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               22641 non-null  int64 \n",
      " 1   Clothing ID              22641 non-null  int64 \n",
      " 2   Age                      22641 non-null  int64 \n",
      " 3   Title                    19675 non-null  object\n",
      " 4   Review Text              22641 non-null  object\n",
      " 5   Rating                   22641 non-null  int64 \n",
      " 6   Recommended IND          22641 non-null  int64 \n",
      " 7   Positive Feedback Count  22641 non-null  int64 \n",
      " 8   Division Name            22628 non-null  object\n",
      " 9   Department Name          22628 non-null  object\n",
      " 10  Class Name               22628 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 413778 entries, 0 to 413839\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Product Name  413778 non-null  object \n",
      " 1   Brand Name    348623 non-null  object \n",
      " 2   Price         407848 non-null  float64\n",
      " 3   Rating        413778 non-null  int64  \n",
      " 4   Reviews       413778 non-null  object \n",
      " 5   Review Votes  401482 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 22.1+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_clothing_df = clothing_df.dropna(subset=[\"Review Text\"])\n",
    "cleaned_clothing_df.info()\n",
    "\n",
    "cleaned_mobile_phones_df = mobile_phones_df.dropna(subset=[\"Reviews\"])\n",
    "cleaned_mobile_phones_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_food_vectorized = vectorizer.transform(fine_food_df[\"Text\"])\n",
    "play_store_vectorized = vectorizer.transform(play_store_df[\"content\"])\n",
    "clothing_vectorized = vectorizer.transform(cleaned_clothing_df[\"Review Text\"])\n",
    "mobile_phones_vectorized = vectorizer.transform(cleaned_mobile_phones_df[\"Reviews\"])\n",
    "\n",
    "y_rating_ff = fine_food_df[\"Score\"]\n",
    "y_rating_ps = play_store_df[\"score\"]\n",
    "y_rating_cl = cleaned_clothing_df[\"Rating\"]\n",
    "y_rating_mp = cleaned_mobile_phones_df[\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating_to_sentiment_score(rating):\n",
    "    if rating in [1,2]:\n",
    "        return 1\n",
    "    elif rating in [3]:\n",
    "        return 2\n",
    "    elif rating in [4,5]:\n",
    "        return 3\n",
    "    return -1\n",
    "\n",
    "y_sentiment_ff = y_rating_ff.apply(map_rating_to_sentiment_score)    \n",
    "y_sentiment_ps = y_rating_ps.apply(map_rating_to_sentiment_score)\n",
    "y_sentiment_cl = y_rating_cl.apply(map_rating_to_sentiment_score)    \n",
    "y_sentiment_mp = y_rating_mp.apply(map_rating_to_sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    'Amazon Fine Food Reviews',\n",
    "    'Google Play Store Reviews',\n",
    "    'Women\\'s E-Commerce Clothing Reviews',\n",
    "    'Amazon Reviews of Unlocked Mobile Phones'\n",
    "]\n",
    "dataset_x = {\n",
    "    'Amazon Fine Food Reviews': fine_food_vectorized,\n",
    "    'Google Play Store Reviews': play_store_vectorized,\n",
    "    'Women\\'s E-Commerce Clothing Reviews': clothing_vectorized,\n",
    "    'Amazon Reviews of Unlocked Mobile Phones': mobile_phones_vectorized\n",
    "}\n",
    "dataset_y_rating = {\n",
    "    'Amazon Fine Food Reviews': y_rating_ff,\n",
    "    'Google Play Store Reviews': y_rating_ps,\n",
    "    'Women\\'s E-Commerce Clothing Reviews': y_rating_cl,\n",
    "    'Amazon Reviews of Unlocked Mobile Phones': y_rating_mp\n",
    "}\n",
    "dataset_y_sentiment = {\n",
    "    'Amazon Fine Food Reviews': y_sentiment_ff,\n",
    "    'Google Play Store Reviews': y_sentiment_ps,\n",
    "    'Women\\'s E-Commerce Clothing Reviews': y_sentiment_cl,\n",
    "    'Amazon Reviews of Unlocked Mobile Phones': y_sentiment_mp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Decision Tree Model (Rating) on Amazon Fine Food Reviews...\n",
      "Performance:\n",
      "- Accuracy: 53.02\n",
      "- F1: 52.19\n",
      "- Test Prediction Time: 0.17s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.27      0.26     52268\n",
      "           2       0.15      0.01      0.01     29769\n",
      "           3       0.18      0.12      0.15     42640\n",
      "           4       0.20      0.29      0.24     80655\n",
      "           5       0.71      0.71      0.71    363122\n",
      "\n",
      "    accuracy                           0.53    568454\n",
      "   macro avg       0.30      0.28      0.27    568454\n",
      "weighted avg       0.52      0.53      0.52    568454\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Sentiment) on Amazon Fine Food Reviews...\n",
      "Performance:\n",
      "- Accuracy: 76.22\n",
      "- F1: 72.44\n",
      "- Test Prediction Time: 0.13s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.27      0.31     82037\n",
      "           2       0.23      0.02      0.04     42640\n",
      "           3       0.82      0.92      0.87    443777\n",
      "\n",
      "    accuracy                           0.76    568454\n",
      "   macro avg       0.47      0.41      0.41    568454\n",
      "weighted avg       0.71      0.76      0.72    568454\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Rating) on Google Play Store Reviews...\n",
      "Performance:\n",
      "- Accuracy: 29.59\n",
      "- F1: 22.27\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.22      0.28      2506\n",
      "           2       0.60      0.00      0.00      2344\n",
      "           3       0.27      0.05      0.08      1991\n",
      "           4       0.38      0.20      0.26      2775\n",
      "           5       0.27      0.87      0.41      2879\n",
      "\n",
      "    accuracy                           0.30     12495\n",
      "   macro avg       0.38      0.27      0.21     12495\n",
      "weighted avg       0.38      0.30      0.22     12495\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Sentiment) on Google Play Store Reviews...\n",
      "Performance:\n",
      "- Accuracy: 52.08\n",
      "- F1: 42.50\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.21      0.33      4850\n",
      "           2       0.40      0.00      0.01      1991\n",
      "           3       0.50      0.97      0.66      5654\n",
      "\n",
      "    accuracy                           0.52     12495\n",
      "   macro avg       0.53      0.39      0.33     12495\n",
      "weighted avg       0.56      0.52      0.42     12495\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Rating) on Women's E-Commerce Clothing Reviews...\n",
      "Performance:\n",
      "- Accuracy: 50.29\n",
      "- F1: 43.17\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.21      0.13       821\n",
      "           2       0.22      0.00      0.01      1549\n",
      "           3       0.26      0.06      0.09      2823\n",
      "           4       0.25      0.11      0.15      4908\n",
      "           5       0.58      0.84      0.69     12540\n",
      "\n",
      "    accuracy                           0.50     22641\n",
      "   macro avg       0.28      0.24      0.21     22641\n",
      "weighted avg       0.43      0.50      0.43     22641\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Sentiment) on Women's E-Commerce Clothing Reviews...\n",
      "Performance:\n",
      "- Accuracy: 74.51\n",
      "- F1: 68.72\n",
      "- Test Prediction Time: 0.00s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.18      0.20      2370\n",
      "           2       0.18      0.01      0.03      2823\n",
      "           3       0.79      0.94      0.86     17448\n",
      "\n",
      "    accuracy                           0.75     22641\n",
      "   macro avg       0.41      0.38      0.36     22641\n",
      "weighted avg       0.66      0.75      0.69     22641\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Rating) on Amazon Reviews of Unlocked Mobile Phones...\n",
      "Performance:\n",
      "- Accuracy: 54.03\n",
      "- F1: 50.69\n",
      "- Test Prediction Time: 0.06s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.37      0.45     72337\n",
      "           2       0.13      0.00      0.01     24724\n",
      "           3       0.22      0.13      0.16     31763\n",
      "           4       0.25      0.27      0.26     61374\n",
      "           5       0.63      0.79      0.70    223580\n",
      "\n",
      "    accuracy                           0.54    413778\n",
      "   macro avg       0.36      0.31      0.31    413778\n",
      "weighted avg       0.50      0.54      0.51    413778\n",
      "\n",
      "\n",
      "\n",
      "Testing Decision Tree Model (Sentiment) on Amazon Reviews of Unlocked Mobile Phones...\n",
      "Performance:\n",
      "- Accuracy: 74.78\n",
      "- F1: 69.90\n",
      "- Test Prediction Time: 0.06s\n",
      "- Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.38      0.48     97061\n",
      "           2       0.25      0.01      0.02     31763\n",
      "           3       0.76      0.96      0.85    284954\n",
      "\n",
      "    accuracy                           0.75    413778\n",
      "   macro avg       0.56      0.45      0.45    413778\n",
      "weighted avg       0.70      0.75      0.70    413778\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    X_dataset = dataset_x[dataset_name]\n",
    "    y_rating_dataset = dataset_y_rating[dataset_name]\n",
    "    y_sentiment_dataset = dataset_y_sentiment[dataset_name]\n",
    "    \n",
    "    ds_start = time.perf_counter()\n",
    "    print(f'\\nTesting Decision Tree Model (Rating) on {dataset_name}...')\n",
    "    ds_predictions = dt_rating_best_clf.predict(X_dataset)\n",
    "    ds_end = time.perf_counter()\n",
    "    ds_accuracy = accuracy_score(y_rating_dataset, ds_predictions)\n",
    "    ds_f1 = f1_score(y_rating_dataset, ds_predictions, average='weighted', zero_division=0)\n",
    "    print(f'Performance:')\n",
    "    print(f'- Accuracy: {ds_accuracy*100:.2f}')\n",
    "    print(f'- F1: {ds_f1*100:.2f}')\n",
    "    print(f'- Test Prediction Time: {ds_end - ds_start:.2f}s')\n",
    "    print(f'- Classification Report:')\n",
    "    print(classification_report(y_rating_dataset, ds_predictions, zero_division=0))\n",
    "    print()\n",
    "\n",
    "\n",
    "    ds_start = time.perf_counter()\n",
    "    print(f'\\nTesting Decision Tree Model (Sentiment) on {dataset_name}...')\n",
    "    ds_predictions = dt_sentiment_best_clf.predict(X_dataset)\n",
    "    ds_end = time.perf_counter()\n",
    "    ds_accuracy = accuracy_score(y_sentiment_dataset, ds_predictions)\n",
    "    ds_f1 = f1_score(y_sentiment_dataset, ds_predictions, average='weighted', zero_division=0)\n",
    "    print(f'Performance:')\n",
    "    print(f'- Accuracy: {ds_accuracy*100:.2f}')\n",
    "    print(f'- F1: {ds_f1*100:.2f}')\n",
    "    print(f'- Test Prediction Time: {ds_end - ds_start:.2f}s')\n",
    "    print(f'- Classification Report:')\n",
    "    print(classification_report(y_sentiment_dataset, ds_predictions, zero_division=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
